{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise2Void - 2D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Please install TensorFlow: https://www.tensorflow.org/install/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/projects/n2v/Noise2Void/gitrepos/Noise2Void/csbdeep/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6dd4c9ea21af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcsbdeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCARE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcsbdeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_some\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcsbdeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn2v_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmanipulate_val_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/n2v/Noise2Void/gitrepos/Noise2Void/csbdeep/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mraise_from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please install TensorFlow: https://www.tensorflow.org/install/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/progs/miniconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Please install TensorFlow: https://www.tensorflow.org/install/"
     ]
    }
   ],
   "source": [
    "from csbdeep.models import Config, CARE\n",
    "import numpy as np\n",
    "from csbdeep.utils import plot_some, plot_history\n",
    "from csbdeep.utils.n2v_utils import manipulate_val_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "\n",
    "if not os.path.exists('./data/N2V_exampleData.zip'):\n",
    "    data = urllib.request.urlretrieve('https://cloud.mpi-cbg.de/index.php/s/KKPX20qD05vp60F/download', './data/N2V_exampleData.zip')\n",
    "    with zipfile.ZipFile('./data/N2V_exampleData.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./data/N2V_exampleData')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Noise2Void with the CARE framework we have to switch the <code>train_scheme</code> from <code>'CARE'</code> to <code>'Noise2Void'</code>. This will turn on the pixel-masking which is needed for Noise2Void training. Furhtermore it is recommended to increase the <code>train_batch_size</code> and enable <code>batch_norm</code>. \n",
    "\n",
    "To keep the network from learning the identity we have to manipulate the input pixels during training. For this we have the parameter <code>n2v_manipulator</code> with default value <code>'uniform_withCP'</code>. Most pixel manipulators will compute the replacement value based on a neighborhood. With <code>n2v_neighborhood_radius</code> we can control its size. \n",
    "\n",
    "Other pixel manipulators:\n",
    "* normal_withoutCP: samples the neighborhood according to a normal gaussian distribution, but without the center pixel\n",
    "* normal_additive: adds a random number to the original pixel value. The random number is sampled from a gaussian distribution with zero-mean and sigma = <code>n2v_neighborhood_radius</code>\n",
    "* normal_fitted: uses a random value from a gaussian normal distribution with mean equal to the mean of the neighborhood and standard deviation equal to the standard deviation of the neighborhood.\n",
    "* identity: performs no pixel manipulation\n",
    "\n",
    "For faster training multiple pixels per input patch can be manipulated. In our experiments we manipulated about 1.6% of the input pixels per patch. For a patch size of 64 by 64 pixels we manipulated <code>n2v_num_pix</code> = 64 pixels simultaniously. \n",
    "\n",
    "For Noise2Void training it is possible to pass arbitrarily large patches to the training method. From these patches random subpatches of size <code>n2v_patch_shape</code> are extracted during training. Default patch shape is set to (64, 64).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can increase \"train_steps_per_epoch\" to get even better results at the price of longer computation. \n",
    "config = Config('SYXC', n_channel_in=1, n_channel_out=1, unet_kern_size = 3, train_steps_per_epoch=50, train_loss='mse',\n",
    "                batch_norm = True, train_scheme = 'Noise2Void', train_batch_size = 128, n2v_num_pix = 64,\n",
    "                n2v_patch_shape = (64, 64), n2v_manipulator = 'uniform_withCP', n2v_neighborhood_radius='5')\n",
    "\n",
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config, 'n2v_2D', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we load __one__ set of low-SNR images and normalize them to 0-mean and 1-std. This data is used as input data and stored in the variable <code>X</code>. Our target <code>Y</code> is <code>X</code> concatenated with a zero-tensor of the same shape. This zero-tensor is used for the masking of the pixels during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to normalize the data before we feed it into our network, and denormalize it afterwards.\n",
    "def normalize(img, mean, std):\n",
    "    zero_mean = img - mean\n",
    "    return zero_mean/std\n",
    "\n",
    "def denormalize(x, mean, std):\n",
    "    return x*std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lowSNR data. Note: This can be the same data as we test on. \n",
    "# Leave couple slices for validation ;)\n",
    "X = X = np.load('data/N2V_exampleData/N2V_lowSNR.npy')[:240,...]\n",
    "\n",
    "mean, std = np.mean(X), np.std(X)\n",
    "X = normalize(X, mean, std)\n",
    "\n",
    "# We concatenate an extra channel filled with zeros. It will be internally used for the masking.\n",
    "Y = np.concatenate((X, np.zeros(X.shape)), axis=3)\n",
    "\n",
    "# All training images are noisy:\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.imshow(Y[0,...,0], cmap=\"magma\")\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data Preparation\n",
    "\n",
    "There are two possiblities to build the validation set:\n",
    "\n",
    "1. Training-Data like: Meaning that the validations loss is only computed on a fixed number of manipulated (masked) pixels. This means that we randomly select a fixed number of pixels before training and manipulate them like it is done for the training data during training. \n",
    "2. Test-Data like: Meaning that the validation loss is computed on all __not__ manipulated pixels of the validation set. This setup is more like the setup during testing.\n",
    "\n",
    "In our paper we chose option (1) to have the same loss during validation as during training. But using option (2) will result in a more stable validation loss since it is computed over __all__ instead of a subset of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the remaining data as validation data\n",
    "X_val = np.load('data/N2V_exampleData/N2V_lowSNR.npy')[240:,...]\n",
    "X_val = normalize(X_val, mean, std)\n",
    "\n",
    "# 1. Option\n",
    "Y_val = np.concatenate((X_val.copy(), np.zeros(X_val.shape)), axis=3) \n",
    "manipulate_val_data(X_val, Y_val,num_pix=256*256/64 , shape=(256, 256))\n",
    "\n",
    "# 2. Option\n",
    "#Y_val = np.concatenate((X_val.copy(), np.ones(X_val.shape)), axis=3)\n",
    "\n",
    "# The validation set is noisy as well:\n",
    "\n",
    "plt.figure(figsize=(25,25))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X_val[0,...,0], cmap=\"magma\")\n",
    "plt.title(\"Manipulated Image\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(Y_val[0,...,1], cmap=\"gray\")\n",
    "plt.title(\"Mask\")\n",
    "print(X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.train(X,Y, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the evaluation we load the test low-SNR and ground truth data. Since we have simulated low- and high-SNR images via exposure, we have to normalize the values to compute a meaningful PSNR value. The ground truth data has a simulated exposure of 10'000 and the low-SNR data has an exposure of 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights( name='weights_now.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gt = np.load('data/N2V_exampleData/N2V_gt.npy')\n",
    "# Normalize exposure\n",
    "test_gt = test_gt/10000 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lowSNR = np.load('data/N2V_exampleData/N2V_lowSNR.npy')\n",
    "# normalize data with mean and std of the training data\n",
    "test_lowSNR = normalize(test_lowSNR, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "# Denoise all images\n",
    "for i in range(test_lowSNR.shape[0]):\n",
    "    predictions.append(denormalize(model.predict(test_lowSNR[i], axes='YXC',normalizer=None ), mean, std))\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,9))\n",
    "plot_some(test_lowSNR[:5], test_gt[:5], predictions[:5])\n",
    "plt.suptitle('5 example test patches\\n'      \n",
    "             'first row: input (source),  '        \n",
    "             'second row: target (ground truth),  '\n",
    "             'third row: prediction');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(gt, pred, range_):\n",
    "    mse = np.mean((gt - pred)**2)\n",
    "    return 20 * np.log10((range_)/np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_PSNR(gt, pred):\n",
    "    psnr = 0\n",
    "    min_gt, max_gt = np.min(gt), np.max(gt)\n",
    "    for i in range(gt.shape[0]):\n",
    "        psnr += PSNR(gt[i], pred[i], max_gt-min_gt)\n",
    "    \n",
    "    return psnr/gt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PSNR')\n",
    "print('Input:', stack_PSNR(test_gt, test_lowSNR))\n",
    "print('Prediction:', stack_PSNR(test_gt, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
