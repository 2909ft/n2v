{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise2Void - 3D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csbdeep.models import Config, CARE\n",
    "import numpy as np\n",
    "from csbdeep.utils import plot_some, plot_history\n",
    "from csbdeep.utils.n2v_utils import manipulate_val_data\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import urllib\n",
    "\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "\n",
    "if not os.path.exists('./data/N2V_exampleData3D.zip'):\n",
    "    data = urllib.request.urlretrieve('https://cloud.mpi-cbg.de/index.php/s/JVxU9uiwM5f0Raz/download', './data/N2V_exampleData3D.zip')\n",
    "    with zipfile.ZipFile('./data/N2V_exampleData3D.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./data/N2V_exampleData3D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Noise2Void with the CARE framework we have to switch the <code>train_scheme</code> from <code>'CARE'</code> to <code>'Noise2Void'</code>. This will turn on the pixel-masking which is needed for Noise2Void training. Furhtermore it is recommended to increase the <code>train_batch_size</code> and enable <code>batch_norm</code>. \n",
    "\n",
    "To keep the network from learning the identity we have to manipulate the input pixels during training. For this we have the parameter <code>n2v_manipulator</code> with default value <code>'uniform_withCP'</code>. Most pixel manipulators will compute the replacement value based on a neighborhood. With <code>n2v_neighborhood_radius</code> we can control its size. \n",
    "\n",
    "Other pixel manipulators:\n",
    "* normal_withoutCP: samples the neighborhood according to a normal gaussian distribution, but without the center pixel\n",
    "* normal_additive: adds a random number to the original pixel value. The random number is sampled from a gaussian distribution with zero-mean and sigma = <code>n2v_neighborhood_radius</code>\n",
    "* normal_fitted: uses a random value from a gaussian normal distribution with mean equal to the mean of the neighborhood and standard deviation equal to the standard deviation of the neighborhood.\n",
    "* identity: performs no pixel manipulation\n",
    "\n",
    "For faster training multiple pixels per input patch can be manipulated. In our experiments we manipulated about 1.6% of the input pixels per patch. For a patch size of 64 by 64 pixels we manipulated <code>n2v_num_pix</code> = 64 pixels simultaniously. \n",
    "\n",
    "For Noise2Void training it is possible to pass arbitrarily large patches to the training method. From these patches random subpatches of size <code>n2v_patch_shape</code> are extracted during training. Default patch shape is set to (64, 64).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config('SZYXC', n_channel_in=1, n_channel_out=1, unet_kern_size = 3, train_steps_per_epoch=50, train_loss='mse',\n",
    "                batch_norm = True, train_scheme = 'Noise2Void', train_batch_size = 4, n2v_num_pix = 2048,\n",
    "                n2v_patch_shape = (32, 64, 64), n2v_manipulator = 'uniform_withCP', n2v_neighborhood_radius='5',\n",
    "                train_reduce_lr={'factor': 0.5, 'patience': 20, 'min_delta': 0},\n",
    "                train_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CARE(config=config, name='n2v_3D', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we load __one__ set of low-SNR images and normalize them to 0-mean and 1-std. This data is used as input data and stored in the variable <code>X</code>. Our target <code>Y</code> is <code>X</code> concatenated with a zero-tensor of the same shape. This zero-tensor is used for the masking of the pixels during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to normalize the data before we feed it into our network, and denormalize it afterwards.\n",
    "def normalize(img, mean, std):\n",
    "    zero_mean = img - mean\n",
    "    return zero_mean/std\n",
    "\n",
    "def denormalize(x, mean, std):\n",
    "    return x*std + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "X = np.load('data/N2V_exampleData3D/Fly_train.npy')[...,np.newaxis]\n",
    "mean, std = np.mean(X), np.std(X)\n",
    "X = normalize(X, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We concatenate an extra channel filled with zeros. It will be internally used for the masking.\n",
    "Y = np.concatenate((X, np.zeros(X.shape)), axis=4)\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Data Preparation\n",
    "\n",
    "There are two possiblities to build the validation set:\n",
    "\n",
    "1. Training-Data like: Meaning that the validations loss is only computed on a fixed number of manipulated pixels. This means that we randomly select a fixed number of pixels before training and manipulate them like it will be done during training. \n",
    "2. Test-Data like: Meaning that the validation loss is computed on all __not__ manipulated pixels of the validation set. This setup is more like the setup during testing.\n",
    "\n",
    "In our paper we chose option (1) to have the same loss during validation as during training. But using option (2) will result in a more stable validation loss since it is computed over __all__ instead of a subset of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the validation data\n",
    "X_val = np.load('data/N2V_exampleData3D/Fly_val.npy')[...,np.newaxis]\n",
    "X_val = normalize(X_val, mean, std)\n",
    "\n",
    "# 1. Option (is not implemented yet for 3D data)\n",
    "\n",
    "# 2. Option\n",
    "Y_val = np.concatenate((X_val.copy(), np.ones(X_val.shape)), axis=4)\n",
    "print(X_val.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.train(X,Y, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(history.history.keys())))\n",
    "plt.figure(figsize=(16,5))\n",
    "plot_history(history,['loss','val_loss']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have ground truth data to calculate a PSNR with this data.\n",
    "Instead, we will simply look at the denoised images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially load a model thaht was trained before.\n",
    "\n",
    "model.load_weights( name='weights_last.h5')\n",
    "#model.load_weights( name='weights_now.h5')\n",
    "#model.load_weights( name='weights_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data. \n",
    "test_lowSNR_raw = np.load('data/N2V_exampleData3D/Fly_test.npy')\n",
    "test_lowSNR = normalize(test_lowSNR_raw, mean, std)\n",
    "print(test_lowSNR_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise the image. \n",
    "predictions = denormalize(model.predict(test_lowSNR[0], axes='ZYX',normalizer=None ), mean, std)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets have a look at the results. \n",
    "vmi=np.percentile(predictions,1)\n",
    "vma=np.percentile(predictions,99.9)\n",
    "\n",
    "plt.figure(figsize=(9,15))\n",
    "plt.title('max-projection of raw data')\n",
    "plt.imshow(np.max(test_lowSNR_raw[0],0),vmin=vmi,vmax=vma,cmap=\"magma\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(9,15))\n",
    "plt.title('max-projection of denoised data')\n",
    "plt.imshow(np.max(predictions,0),vmin=vmi,vmax=vma,cmap=\"magma\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
